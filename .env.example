# DSPy Prompt Improver Environment Configuration
# Copy this file to .env and update values as needed

# ============================================
# LLM Provider Configuration
# ============================================
# Options: ollama, gemini, deepseek, openai, anthropic
# Default: anthropic (Haiku 4.5 - fastest & most cost-effective)
LLM_PROVIDER=anthropic

# Model Configuration
# ================
# Anthropic Claude Models:
#   - claude-haiku-4-5-20251001   (Haiku 4.5 - fastest, ~$0.08/1M tokens) âœ“ RECOMMENDED
#   - claude-sonnet-4-5-20250929  (Sonnet 4.5 - balanced, ~$3/1M tokens)
#   - claude-opus-4-20250514      (Opus 4 - highest quality, ~$15/1M tokens)
#
# DeepSeek Models:
#   - deepseek-chat    (Main chat model - lowest cost)
#   - deepseek-reasoner (Reasoning model)
#
# Gemini Models:
#   - gemini-2.0-flash-exp (Fast, experimental)
#   - gemini-2.5-pro      (Latest Pro)
#
# OpenAI Models:
#   - gpt-4o-mini    (Fastest, cheapest)
#   - gpt-4o         (Standard)
#
# Ollama Local Models:
#   - hf.co/mradermacher/Novaeus-Promptist-7B-Instruct-i1-GGUF:Q5_K_M
#   - llama3.2, mistral, or any model pulled with `ollama pull`
LLM_MODEL=claude-haiku-4-5-20251001

# API Base URL (optional - uses provider defaults if omitted)
# For Anthropic, always use: https://api.anthropic.com
LLM_BASE_URL=https://api.anthropic.com

# ============================================
# API Keys (only required for non-Ollama providers)
# ============================================
# Anthropic API Key (required when LLM_PROVIDER=anthropic)
# Get your key from: https://console.anthropic.com/
# Supports both ANTHROPIC_API_KEY and HEMDOV_ANTHROPIC_API_KEY
ANTHROPIC_API_KEY=your_anthropic_api_key_here
HEMDOV_ANTHROPIC_API_KEY=your_anthropic_api_key_here

# DeepSeek API Key (required when LLM_PROVIDER=deepseek)
# Get your key from: https://platform.deepseek.com/
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# Gemini API Key (required when LLM_PROVIDER=gemini)
# GEMINI_API_KEY=your_gemini_api_key_here

# OpenAI API Key (required when LLM_PROVIDER=openai)
# OPENAI_API_KEY=your_openai_api_key_here

# Generic API Key (fallback if provider-specific key not set)
# LLM_API_KEY=your_generic_api_key_here

# ============================================
# SQLite Persistence Configuration
# ============================================
# Master switch for prompt history tracking
SQLITE_ENABLED=true

# Database file location (relative to project root)
SQLITE_DB_PATH=data/prompt_history.db

# Connection pool size (SQLite: 1 is optimal due to file-locking)
SQLITE_POOL_SIZE=1

# Auto-delete records older than N days (0 = disable)
SQLITE_RETENTION_DAYS=30

# Run cleanup on startup (removes expired records)
SQLITE_AUTO_CLEANUP=true

# Write-Ahead Logging for better concurrency (recommended)
SQLITE_WAL_MODE=true

# ============================================
# DSPy Configuration
# ============================================
DSPY_MAX_BOOTSTRAPPED_DEMOS=5
DSPY_MAX_LABELED_DEMOS=3
DSPY_COMPILED_PATH=

# ============================================
# API Server Configuration
# ============================================
API_HOST=0.0.0.0
API_PORT=8000
API_RELOAD=true

# ============================================
# Quality Thresholds
# ============================================
MIN_CONFIDENCE_THRESHOLD=0.7
MAX_LATENCY_MS=30000
