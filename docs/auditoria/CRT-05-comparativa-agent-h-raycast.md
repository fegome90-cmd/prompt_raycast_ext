# CRT-05: Comparativa de Implementaciones - Raycast vs Agent_H

**Fecha:** 2026-01-02
**Severidad:** ðŸ“Š AnÃ¡lisis Comparativo
**Estado:** âœ… Completado
**ID:** CRT-05 (Critical Technical Report)

---

## 1. Resumen Ejecutivo

Se investigÃ³ el cÃ³digo en `agent_h/eval` y `agent_h/hemdov/src` para entender cÃ³mo implementan la integraciÃ³n con DeepSeek y LiteLLM. El objetivo es aprender de la implementaciÃ³n existente para mejorar el sistema de Raycast.

**Hallazgo principal:** `agent_h` tiene una arquitectura mÃ¡s madura con:
- âœ… Sistema de evaluaciÃ³n robusto
- âœ… LiteLLM router con fallback chain
- âœ… ConfiguraciÃ³n centralizada en YAML
- âœ… Tests DSPy completos

---

## 2. Arquitectura en Agent_H

### 2.1 Estructura de Directorios

```
agent_h/
â”œâ”€â”€ eval/                          # Sistema de evaluaciÃ³n
â”‚   â”œâ”€â”€ adapters/                   # Adaptadores de routers
â”‚   â”‚   â”œâ”€â”€ router_adapter.py       # StubRouter, safe_call wrapper
â”‚   â”‚   â””â”€â”€ router_entrypoint.py    # Carga de entrypoints dinÃ¡micos
â”‚   â”œâ”€â”€ benchmarks/                 # Benchmarks de tool routing
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ eval_config.yaml        # ConfiguraciÃ³n centralizada
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â””â”€â”€ router_eval_core.py     # Core de evaluaciÃ³n
â”‚   â””â”€â”€ tests/
â”‚       â”œâ”€â”€ test_dspy_lm_config.py  # Tests DSPy LM
â”‚       â””â”€â”€ test_dspy_integration.py # Tests integraciÃ³n
â”‚
â””â”€â”€ hemdov/src/                    # Sistema principal HemDov
    â””â”€â”€ hemdov/
        â”œâ”€â”€ infrastructure/
        â”‚   â””â”€â”€ adapters/
        â”‚       â”œâ”€â”€ litellm_dspy_adapter.py      # DSPy â† LiteLLM
        â”‚       â”œâ”€â”€ litellm_router.py             # Router con fallback
        â”‚       â”œâ”€â”€ litellm_executor_adapter.py   # Executor adapter
        â”‚       â”œâ”€â”€ deepseek_llm.py               # DeepSeek directo
        â”‚       â””â”€â”€ litellm_llm_client.py         # Cliente LiteLLM
        â””â”€â”€ application/
            â””â”€â”€ ports/
                â””â”€â”€ llm_client.py                 # Puerto LLMClient
```

### 2.2 Archivos Clave Analizados

#### 2.2.1 DeepSeek LLM Client

**`hemdov/src/hemdov/infrastructure/adapters/deepseek_llm.py`**

```python
class DeepseekLLMClient(LLMClient):
    """LLM implementation using Deepseek API (OpenAI-compatible)."""

    def __init__(
        self,
        api_key: str,
        model: str = "deepseek-chat",
        base_url: str = "https://api.deepseek.com/v1",
    ):
        self._api_key = api_key
        self._model = model
        self._base_url = base_url

    def generate(
        self,
        prompt: str,
        system: str | None = None,
        timeout: float = 120.0,
        silent: bool = False,
        **kwargs,
    ) -> str:
        """Generate text response using Deepseek API."""
        # Llamada HTTP directa a API de DeepSeek
        # Temperature: 0.0 (mÃ¡xima consistencia)
        # Max tokens: 512
```

**CaracterÃ­sticas:**
- âœ… ImplementaciÃ³n directa HTTP con httpx
- âœ… Temperature 0.0 por defecto
- âœ… Max tokens 512 (ajustable)
- âœ… Timeout configurable (120s default)
- âœ… Sistema/system prompt soportado
- âœ… Manejo de errores robusto

#### 2.2.2 LiteLLM DSPy Adapter

**`hemdov/src/hemdov/infrastructure/adapters/litellm_dspy_adapter.py`**

```python
class LiteLLMDSPyAdapter(dspy.LM):
    """Adapter that makes LiteLLM router work as DSPy language model."""

    def __init__(self, router: LiteLLMRouter, timeout: float | None = None, **kwargs):
        super().__init__(model="litellm-router", **kwargs)
        self._router = router
        self._timeout = timeout if timeout is not None else Settings().llm_timeout
        self._history = []

    def __call__(
        self,
        prompt: str | None = None,
        messages: list[dict] | None = None,
        **kwargs
    ) -> list[str]:
        """DSPy calls this method for text generation."""
        # Soporta ambos estilos DSPy:
        # - DSPy 2.x: prompt string
        # - DSPy 3.x: messages list

        # Ejecuta via router con fallback chain
        response = self._router.execute(
            messages=messages,
            task_type=task_type,
            timeout=self._timeout,
            max_retries=1,  # FallbackChain retries
            num_retries=0,  # LiteLLM retries
            **kwargs
        )

        return [response['content']] * n
```

**CaracterÃ­sticas:**
- âœ… Compatible con DSPy 2.x y 3.x
- âœ… Historial de llamadas para debugging
- âœ… Task type differentiation
- âœ… ConfiguraciÃ³n de timeouts robusta
- âœ… Retries configurables

#### 2.2.3 DSPy LM Configuration Tests

**`eval/tests/test_dspy_lm_config.py`**

```python
def test_deepseek_lm_config(self):
    """Test Deepseek (OpenAI-compatible) LM configuration."""
    import dspy

    lm = dspy.LM(
        model="openai/deepseek-chat",
        api_key="test-key-12345",
        api_base="https://api.deepseek.com/v1",
        temperature=0.0,
        max_tokens=1024
    )

    assert lm is not None

def test_configure_sets_default_lm(self):
    """Test dspy.configure() sets default LM."""
    import dspy

    lm = dspy.LM(model="openai/gpt-3.5-turbo", api_key="dummy")
    dspy.configure(lm=lm)

    assert dspy.settings.lm is not None
```

**CaracterÃ­sticas:**
- âœ… Tests unitarios de configuraciÃ³n DSPy
- âœ… Tests de mÃºltiples configuraciones
- âœ… Tests de integraciÃ³n con BaselineExecutor
- âœ… Runtime <5 segundos (rÃ¡pido feedback)

#### 2.2.4 EvaluaciÃ³n Config

**`eval/config/eval_config.yaml`**

```yaml
providers:
  qwen_local:
    kind: "ollama"
    model: "qwen3-coder:30b"
    base_url: "http://localhost:11434"
    cost_per_million_in: 0.0
    cost_per_million_out: 0.0

  gemini_flash:
    kind: "gemini"
    model: "gemini-2.0-flash"
    api_key_env: "GEMINI_API_KEY"
    cost_per_million_in: 0.10
    cost_per_million_out: 0.40

run:
  temperature: 0.0
  max_tokens:
    guionista: 1200
    executor: 350
    router: 180

thresholds:
  executor:
    schema_strict_pass: 0.98
    no_preamble_pass: 1.00
    action_gate_passed: 0.95
```

**CaracterÃ­sticas:**
- âœ… ConfiguraciÃ³n declarativa en YAML
- âœ… MÃºltiples providers con costos
- âœ… Umbrales de calidad configurables
- âœ… Temperature global 0.0
- âœ… Max tokens por componente

---

## 3. Comparativa: Raycast vs Agent_H

### 3.1 ImplementaciÃ³n DeepSeek

| Aspecto | Raycast (raycast_ext) | Agent_H |
|---------|----------------------|----------|
| **IntegraciÃ³n DeepSeek** | Via LiteLLM en hemdov | Via LiteLLM + HTTP directo |
| **Adaptador DSPy** | âœ… `litellm_dspy_adapter_prompt.py` | âœ… `litellm_dspy_adapter.py` |
| **Cliente HTTP propio** | âŒ No | âœ… `deepseek_llm.py` |
| **Tests DSPy** | âŒ No | âœ… `test_dspy_lm_config.py` |
| **ConfiguraciÃ³n YAML** | âŒ No (solo .env) | âœ… `eval_config.yaml` |
| **Temperature default** | 0.3 | 0.0 |
| **Max tokens** | 2000 | 512-1200 (por componente) |

### 3.2 Sistema de EvaluaciÃ³n

| Aspecto | Raycast | Agent_H |
|---------|---------|----------|
| **Evaluador propio** | âœ… `scripts/evaluator.ts` | âœ… Sistema completo en `eval/` |
| **Tests variabilidad** | âœ… `test-variability.ts` | âœ… Tests DSPy integration |
| **ConfiguraciÃ³n thresholds** | En cÃ³digo (`defaults.ts`) | En YAML (`eval_config.yaml`) |
| **Quality gates** | âœ… jsonValidPass1, copyableRate | âœ… schema_strict_pass, action_gate |
| **Reporting** | JSON output | JSON + anÃ¡lisis completo |

### 3.3 ConfiguraciÃ³n de Providers

| Aspecto | Raycast | Agent_H |
|---------|---------|----------|
| **Providers soportados** | ollama, gemini, deepseek, openai | ollama, gemini, deepseek, openai |
| **ConfiguraciÃ³n** | `.env` + `defaults.ts` | YAML + Settings class |
| **Fallback mechanism** | Simple (primary â†’ fallback) | Complejo (FallbackChain) |
| **Cost tracking** | âŒ No | âœ… SÃ­ (cost_per_million_in/out) |

---

## 4. Patrones y Mejores PrÃ¡cticas Identificados

### 4.1 Patrones en Agent_H

#### 4.1.1 Adapter Pattern con Protocolos

```python
class RouterCallable(Protocol):
    def __call__(self, query: str) -> RouterPrediction: ...

class StubRouter:
    def __call__(self, query: str) -> RouterPrediction:
        # ImplementaciÃ³n determinista para testing
```

**Ventajas:**
- âœ… Intercambiable (stub â†’ production)
- âœ… Type safe con Protocol
- âœ… FÃ¡cil de mockear en tests

#### 4.1.2 Safe Call Wrapper

```python
def safe_call(router: RouterCallable, query: str) -> RouterPrediction:
    """Wrap router call to prevent eval crash on exceptions."""
    try:
        pred = router(query)
        tools = normalize_tools(pred.tools)
        errs = consistency_checks(tools)
        # ... procesamiento con tolerancia a fallos
    except Exception as e:
        return RouterPrediction(tools=[], conf=0.0, raw={"error": str(e)})
```

**Ventajas:**
- âœ… Eval nunca crash
- âœ…Errores reportados en metadata
- âœ… Latency tracking inclusivo

#### 4.1.3 ConfiguraciÃ³n Declarativa YAML

```yaml
providers:
  deepseek_chat:
    kind: "deepseek"
    model: "deepseek-chat"
    api_key_env: "DEEPSEEK_API_KEY"
    cost_per_million_in: 0.14
    cost_per_million_out: 0.28
```

**Ventajas:**
- âœ… FÃ¡cil de modificar sin cÃ³digo
- âœ… Versionable en git
- âœ… DocumentaciÃ³n inline
- âœ… MÃºltiples environments

### 4.2 Patrones en Raycast

#### 4.2.1 Type-Safe Config con Zod

```typescript
const DEFAULTS = {
  ollama: {
    model: "hf.co/...",
    temperature: 0.1,
    timeoutMs: 30_000,
  }
} as const;

type Defaults = typeof DEFAULTS;
```

**Ventajas:**
- âœ… Type safety completo
- âœ… Autocompletado en IDE
- âœ… Single source of truth

#### 4.2.2 Test de Variabilidad EmpÃ­rico

```typescript
// Ejecuta mismo input 10 veces
const results = await Promise.all(
  Array(RUNS).fill(null).map(() =>
    improvePromptWithOllama({ rawInput: input })
  )
);

// Calcula similitud Jaccard
const similarity = jaccardSimilarity(results[0], results[1]);
```

**Ventajas:**
- âœ… Datos empÃ­ricos reales
- âœ… Cuantifica variabilidad
- âœ… Reproducible

---

## 5. Recomendaciones para Raycast

### 5.1 Prioridad Alta: Migrar a DeepSeek

**AcciÃ³n inmediata:**
1. Usar adaptador existente en hemdov
2. Configurar temperature 0.0
3. Ejecutar test de variabilidad para validar

**CÃ³digo de referencia:**
```python
# En raycast_ext/hemdov/infrastructure/config/__init__.py
class Settings(BaseSettings):
    LLM_PROVIDER: str = "deepseek"  # Cambiar de "ollama"
    LLM_MODEL: str = "deepseek-chat"
    DEEPSEEK_API_KEY: Optional[str] = None
```

### 5.2 Prioridad Media: Agregar Tests DSPy

**Crear:** `dashboard/tests/dspystuff/deepseek_integration.test.ts`

```typescript
describe('DeepSeek Integration', () => {
  it('should configure DSPy with DeepSeek', async () => {
    const lm = create_deepseek_adapter(
      model="deepseek-chat",
      api_key=process.env.DEEPSEEK_API_KEY,
      temperature=0.0
    );

    const response = await lm("Test prompt");
    expect(response).toBeDefined();
    expect(response.length).toBeGreaterThan(0);
  });
});
```

### 5.3 Prioridad Media: ConfiguraciÃ³n YAML

**Crear:** `dashboard/config/eval_config.yaml`

```yaml
providers:
  deepseek_chat:
    kind: "deepseek"
    model: "deepseek-chat"
    api_key_env: "DEEPSEEK_API_KEY"
    temperature: 0.0
    max_tokens: 2000

quality_gates:
  json_valid_pass1: 0.90
  copyable_rate: 0.90
  latency_p95_max: 5000
```

### 5.4 Prioridad Baja: Safe Call Wrapper

**Agregar a:** `dashboard/src/core/llm/improvePrompt.ts`

```typescript
export async function safeImprovePrompt(
  input: string,
  options: ImproveOptions
): Promise<ImproveResult | { error: string }> {
  try {
    return await improvePromptWithOllama(input, options);
  } catch (e) {
    return {
      error: `${e.name}: ${e.message}`,
      improvedPrompt: "",
      metadata: { latencyMs: 0, attempt: 1 }
    };
  }
}
```

---

## 6. Lecciones Aprendidas

### 6.1 Arquitectura

1. **SeparaciÃ³n de concerns:** Agent_H separa evaluaciÃ³n (`eval/`) del sistema principal (`hemdov/`)
2. **Adapters over hardcoding:** Todo es intercambiable vÃ­a adapters
3. **ConfiguraciÃ³n externa:** YAML > hardcoded constants

### 6.2 Testing

1. **Tests rÃ¡pidos:** Agent_H tests corren en <5 segundos
2. **Stubs para testing:** `StubRouter` permite testing sin API calls
3. **Tests de integraciÃ³n:** Validan DSPy + LLM juntos

### 6.3 DeepSeek Specifics

1. **Temperature 0.0:** Agent_H usa 0.0 para mÃ¡xima consistencia
2. **Max tokens bajo:** 512-1200 vs 2000 en Raycast (mÃ¡s rÃ¡pido)
3. **HTTP directo:** `deepseek_llm.py` como alternativa a LiteLLM

### 6.4 EvaluaciÃ³n

1. **Umbrales explÃ­citos:** Todo estÃ¡ cuantificado en YAML
2. **Cost tracking:** Seguimiento de costos por provider
3. **Quality gates:** EspecÃ­ficos por componente (router, executor, etc.)

---

## 7. Plan de AcciÃ³n

### 7.1 Inmediato (Hoy)

1. âœ… Revisar cÃ³digo agent_h (completado)
2. â³ Configurar DeepSeek en raycast_ext
3. â³ Ejecutar test de variabilidad con DeepSeek

### 7.2 Corto Plazo (Esta semana)

4. â³ Migrar tests DSPy de agent_h a raycast
5. â³ Implementar safe_call wrapper
6. â³ Crear config YAML para thresholds

### 7.3 Medio Plazo (Este mes)

7. â³ Unificar sistemas de evaluaciÃ³n
8. â³ Implementar cost tracking
9. â³ Agregar mÃ¡s providers (Claude, etc.)

---

## 8. ConclusiÃ³n

**Agent_H tiene una implementaciÃ³n mÃ¡s madura y robusta** que puede servir de referencia para mejorar Raycast:

**Fortalezas de Agent_H:**
- âœ… Arquitectura limpia con separaciÃ³n de concerns
- âœ… Testing completo y rÃ¡pido
- âœ… ConfiguraciÃ³n flexible en YAML
- âœ… IntegraciÃ³n DeepSeek probada
- âœ… Safe wrappers para tolerancia a fallos

**Fortalezas de Raycast:**
- âœ… Test de variabilidad empÃ­rico (Ãºnico)
- âœ… Type safety con Zod/TypeScript
- âœ… Single source of truth (defaults.ts)

**RecomendaciÃ³n:** Combinar lo mejor de ambos mundos:
- Mantener type safety de Raycast
- Adoptar testing de Agent_H
- Implementar safe wrappers
- Migrar a DeepSeek con temperature 0.0

---

**Analizado por:** ComparaciÃ³n de cÃ³digo agent_h vs raycast_ext
**Fecha:** 2026-01-02
**PrÃ³ximo paso:** Implementar migraciÃ³n a DeepSeek en raycast_ext
