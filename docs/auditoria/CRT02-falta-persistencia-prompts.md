# CRT-02: Falta de Persistencia de Prompts

**Fecha:** 2026-01-02
**Severidad:** ğŸ”´ Alta
**Estado:** âš ï¸ Activo (sin implementar)
**ID:** CRT-02 (Critical Technical Report)

---

## 1. Resumen Ejecutivo

El sistema **no persiste ningÃºn dato** sobre los prompts procesados. Cada request es completamente stateless - no hay historial, no hay logs estructurados, no hay base de datos. Esto imposibilita:

- AnÃ¡lisis de uso y tendencias
- Debugging de problemas posteriores
- Mejora continua basada en datos
- AuditorÃ­a de actividad

**Impacto Actual:** Medio - el sistema funciona pero no hay rastro
**Riesgo Futuro:** Alto - imposibilita anÃ¡lisis y mejora

---

## 2. Estado Actual de Persistencia

### 2.1 Matriz de Almacenamiento

| Tipo de Dato | Â¿Persiste? | UbicaciÃ³n | Volatilidad |
|--------------|-----------|-----------|-------------|
| **ConfiguraciÃ³n** | âœ… SÃ­ | `.env` + Raycast Preferences | Permanente |
| **Prompts de entrada** | âŒ No | - | Se pierde |
| **Prompts mejorados** | âŒ No | - | Se pierde |
| **MÃ©tricas de calidad** | âŒ No | - | Se pierde |
| **Logs de errores** | âŒ No | Stdout (temporal) | Se pierde |
| **Backend usado** | âŒ No | - | Se pierde |
| **Latencia** | âŒ No | - | Se pierde |
| **Metadata** | âŒ No | - | Se pierde |

### 2.2 Flujo de Datos Actual

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FLUJO DE DATOS (ACTUAL)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Usuario ingresa prompt
    â†“
[Memoria temporal]
    â†“
Procesamiento (DSPy/Ollama)
    â†“
Resultado mostrado al usuario
    â†“
âŒ TODO SE PIERDE
    â†“
No hay rastro de lo que pasÃ³
```

**Resultado:** Zero knowledge retention

---

## 3. Impacto y Limitaciones

### 3.1 Impacto Operativo

| Aspecto | Impacto | DescripciÃ³n |
|---------|---------|-------------|
| **Debugging** | ğŸ”´ CrÃ­tico | No se pueden investigar problemas post-hoc |
| **AnÃ¡lisis** | ğŸ”´ CrÃ­tico | Imposible saber quÃ© prompts se usan mÃ¡s |
| **Mejora** | ğŸŸ¡ Alto | No se puede medir mejora over time |
| **AuditorÃ­a** | ğŸŸ¡ Alto | No hay registro de actividad |
| **UX** | ğŸŸ¢ Bajo | Usuario no nota diferencia |

### 3.2 Casos de Uso Imposibles

**1. AnÃ¡lisis de Tendencias**
```python
# âŒ Imposible actualmente
Â¿QuÃ© tipos de prompts se usan mÃ¡s?
Â¿CuÃ¡l es el prompt mÃ¡s largo procesado?
Â¿CuÃ¡ntos prompts fallaron en la Ãºltima semana?
```

**2. Debugging Post-Mortem**
```python
# âŒ Imposible actualmente
"El usuario reportÃ³ un mal output a las 3pm"
â†’ No se puede recuperar el request original
â†’ No se puede reproducir el problema
```

**3. MÃ©tricas de Calidad**
```python
# âŒ Imposible actualmente
Â¿CuÃ¡l es el copyableRate real?
Â¿CuÃ¡ntos repairs se hicieron hoy?
Â¿CuÃ¡l backend se usa mÃ¡s?
```

**4. A/B Testing**
```python
# âŒ Imposible actualmente
Probar cambio en el prompt de mejora
â†’ No se puede comparar antes/despuÃ©s
â†’ No se puede medir impacto
```

---

## 4. AnÃ¡lisis de Requerimientos

### 4.1 Datos que DeberÃ­an Persistirse

**MÃ­nimo viable (MVP):**
```sql
CREATE TABLE prompt_history (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    input_text TEXT NOT NULL,
    output_text TEXT NOT NULL,
    backend TEXT,              -- 'dspy' | 'ollama'
    model_used TEXT,           -- 'Novaeus-Promptist-7B' | ...
    latency_ms INTEGER,
    success BOOLEAN,
    error_message TEXT,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
);
```

**Ideal (completo):**
```sql
CREATE TABLE prompt_history (
    id INTEGER PRIMARY KEY AUTOINCREMENT,

    -- Input
    input_text TEXT NOT NULL,
    input_length INTEGER,
    input_language TEXT,

    -- Output
    output_text TEXT NOT NULL,
    output_length INTEGER,
    improved_prompt TEXT,
    clarifying_questions TEXT,      -- JSON array
    assumptions TEXT,               -- JSON array
    confidence REAL,

    -- Metadata
    backend TEXT,                   -- 'dspy' | 'ollama'
    model_used TEXT,
    preset TEXT,                    -- 'default' | 'specific' | ...
    temperature REAL,

    -- Quality
    used_extraction BOOLEAN,
    used_repair BOOLEAN,
    attempt INTEGER,
    extraction_method TEXT,

    -- Performance
    latency_ms INTEGER,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,

    -- Error handling
    success BOOLEAN,
    error_message TEXT,
    failure_reason TEXT
);

-- Ãndices para queries comunes
CREATE INDEX idx_backend ON prompt_history(backend);
CREATE INDEX idx_timestamp ON prompt_history(timestamp);
CREATE INDEX idx_success ON prompt_history(success);
CREATE INDEX idx_model ON prompt_history(model_used);
```

### 4.2 Consultas Comunes Necesarias

```sql
-- 1. Prompts recientes
SELECT * FROM prompt_history
ORDER BY timestamp DESC
LIMIT 50;

-- 2. Tasas de Ã©xito por backend
SELECT
    backend,
    COUNT(*) as total,
    SUM(CASE WHEN success THEN 1 ELSE 0 END) as successful,
    CAST(SUM(CASE WHEN success THEN 1 ELSE 0 END) AS FLOAT) / COUNT(*) as success_rate
FROM prompt_history
GROUP BY backend;

-- 3. Latencia promedio (P50, P95, P99)
SELECT
    backend,
    AVG(latency_ms) as avg_latency,
    PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY latency_ms) as p50,
    PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY latency_ms) as p95
FROM prompt_history
WHERE success = TRUE
GROUP BY backend;

-- 4. Prompts fallidos recientes
SELECT * FROM prompt_history
WHERE success = FALSE
ORDER BY timestamp DESC
LIMIT 20;

-- 5. Modelos mÃ¡s usados
SELECT
    model_used,
    COUNT(*) as usage_count
FROM prompt_history
GROUP BY model_used
ORDER BY usage_count DESC;
```

---

## 5. Soluciones Propuestas

### 5.1 OpciÃ³n 1: SQLite Local (Recomendada)

**Ventajas:**
- âœ… Zero configuraciÃ³n
- âœ… Embedded en la aplicaciÃ³n
- âœ… Performance excelente para este caso de uso
- âœ… Portabilidad (archivo Ãºnico)
- âœ… SQL completo para anÃ¡lisis

**Desventajas:**
- âš ï¸ Solo acceso local
- âš ï¸ Concurrency limitado (1 writer)

**ImplementaciÃ³n:**

```python
# backend/db/prompt_history.py
import sqlite3
from datetime import datetime
from typing import Optional
import json

class PromptHistory:
    def __init__(self, db_path: str = "prompt_history.db"):
        self.conn = sqlite3.connect(db_path, check_same_thread=False)
        self._create_tables()

    def _create_tables(self):
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS prompt_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                input_text TEXT NOT NULL,
                output_text TEXT NOT NULL,
                backend TEXT,
                model_used TEXT,
                latency_ms INTEGER,
                success BOOLEAN,
                error_message TEXT,
                metadata TEXT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)

    def log_prompt(self, data: dict):
        """Log a prompt processing event."""
        self.conn.execute("""
            INSERT INTO prompt_history (
                input_text, output_text, backend, model_used,
                latency_ms, success, error_message, metadata
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            data["input_text"],
            data["output_text"],
            data.get("backend"),
            data.get("model_used"),
            data.get("latency_ms"),
            data.get("success", True),
            data.get("error_message"),
            json.dumps(data.get("metadata", {}))
        ))
        self.conn.commit()

# Uso en main.py
from backend.db.prompt_history import PromptHistory

history = PromptHistory()

@app.post("/api/v1/improve-prompt")
async def improve_prompt(request: PromptRequest):
    start = time.time()
    try:
        result = await process_prompt(request)
        latency = (time.time() - start) * 1000

        # Log al historial
        history.log_prompt({
            "input_text": request.raw_idea,
            "output_text": result.improved_prompt,
            "backend": "dspy",
            "model_used": settings.LLM_MODEL,
            "latency_ms": latency,
            "success": True,
            "metadata": {
                "confidence": result.confidence,
                "framework": result.framework
            }
        })
        return result
    except Exception as e:
        latency = (time.time() - start) * 1000
        history.log_prompt({
            "input_text": request.raw_idea,
            "output_text": "",
            "backend": "dspy",
            "latency_ms": latency,
            "success": False,
            "error_message": str(e)
        })
        raise
```

### 5.2 OpciÃ³n 2: JSON Lines (Simple)

**Ventajas:**
- âœ… SÃºper simple
- âœ… Human-readable
- âœ… FÃ¡cil de importar a otras herramientas

**Desventajas:**
- âš ï¸ No hay queries
- âš ï¸ Performance pobre para datasets grandes
- âš ï¸ No hay Ã­ndices

**ImplementaciÃ³n:**

```python
# backend/logging/jsonl_logger.py
import json
from datetime import datetime
from pathlib import Path

class JSONLLogger:
    def __init__(self, log_path: str = "logs/prompts.jsonl"):
        self.log_path = Path(log_path)
        self.log_path.parent.mkdir(parents=True, exist_ok=True)

    def log(self, data: dict):
        """Append to JSONL file."""
        data["timestamp"] = datetime.utcnow().isoformat()
        with open(self.log_path, "a") as f:
            f.write(json.dumps(data) + "\n")

# Uso
logger = JSONLLogger()
logger.log({
    "input": request.raw_idea,
    "output": result.improved_prompt,
    "backend": "dspy",
    "latency_ms": latency,
    "success": True
})
```

### 5.3 OpciÃ³n 3: Vector DB (Overkill para ahora)

**No recomendado** hasta que se necesite bÃºsqueda semÃ¡ntica.

---

## 6. ComparaciÃ³n de Soluciones

| Aspecto | SQLite | JSONL | Vector DB |
|---------|--------|-------|-----------|
| **Complejidad** | Media | Baja | Alta |
| **Queries** | âœ… SQL completo | âŒ Ninguna | âœ… BÃºsqueda semÃ¡ntica |
| **Performance** | âœ… Excelente | âš ï¸ Pobre | âœ… Buena |
| **ConfiguraciÃ³n** | âœ… Zero | âœ… Zero | âš ï¸ Requiere setup |
| **Escalabilidad** | âš ï¸ 1 writer | âœ… ilimitado | âœ… Distribuido |
| **Portabilidad** | âœ… 1 archivo | âœ… Texto | âš ï¸ Complejo |
| **Recomendado** | âœ… SÃ­ | Para logging | Futuro |

---

## 7. Plan de ImplementaciÃ³n

### 7.1 Fase 1: MVP con SQLite (Sprint 1)

**Objetivo:** Persistencia bÃ¡sica funcional

- [ ] Crear tabla `prompt_history`
- [ ] Implementar `PromptHistory.log_prompt()`
- [ ] Integrar en endpoint `/api/v1/improve-prompt`
- [ ] Agregar migraciÃ³n inicial
- [ ] Test bÃ¡sico de persistencia

**Archivos a crear:**
```
backend/
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ prompt_history.py      # ORM simple
â”‚   â””â”€â”€ migrations/
â”‚       â””â”€â”€ 001_initial.sql    # CREATE TABLE
```

**Archivos a modificar:**
```
main.py                         # Integrar logging
api/prompt_improver_api.py      # Log en endpoint
```

### 7.2 Fase 2: Analytics Dashboard (Sprint 2)

**Objetivo:** Visualizar datos histÃ³ricos

- [ ] Endpoint `/api/v1/analytics/summary`
- [ ] Endpoint `/api/v1/analytics/recent`
- [ ] Endpoint `/api/v1/analytics/failures`
- [ ] Dashboard simple en Raycast

### 7.3 Fase 3: Advanced Features (Sprint 3)

**Objetivo:** BÃºsqueda y filtrado

- [ ] BÃºsqueda por texto en input/output
- [ ] Filtros por backend, modelo, rango de fechas
- [ ] Export a CSV/JSON
- [ ] Cleanup automÃ¡tico de datos viejos

---

## 8. Consideraciones de Privacy

### 8.1 Datos Sensibles

âš ï¸ **Importante:** Los prompts pueden contener informaciÃ³n sensible:

- CÃ³digo propietario
- InformaciÃ³n corporativa
- Ideas no publicadas
- Datos personales

**Requisitos:**
1. **Local-only:** La DB nunca debe salir de la mÃ¡quina del usuario
2. **Encryption opcional:** Permitir encryptar la DB
3. **Clear data:** BotÃ³n para borrar todo el historial
4. **Explicit consent:** Informar al usuario que se guardan datos

### 8.2 ConfiguraciÃ³n de Privacidad

```typescript
// dashboard/src/core/config/schema.ts
export const configSchema = z.object({
  // ...
  privacy: z.object({
    enableHistory: z.boolean().default(true),
    encryptDatabase: z.boolean().default(false),
    autoCleanupDays: z.number().optional(),
    anonymizeData: z.boolean().default(false),  // Remover texto real
  }),
});
```

---

## 9. Testing y ValidaciÃ³n

### 9.1 Tests de Persistencia

```python
# tests/test_prompt_history.py
def test_prompt_persistence():
    """Verify prompts are saved to DB."""
    history = PromptHistory(":memory:")

    history.log_prompt({
        "input_text": "test input",
        "output_text": "test output",
        "backend": "dspy",
        "success": True
    })

    # Verify
    rows = history.get_recent(10)
    assert len(rows) == 1
    assert rows[0]["input_text"] == "test input"

def test_error_logging():
    """Verify errors are saved."""
    history = PromptHistory(":memory:")

    history.log_prompt({
        "input_text": "bad input",
        "output_text": "",
        "success": False,
        "error_message": "Failed to process"
    })

    failures = history.get_failures(limit=10)
    assert len(failures) == 1
    assert failures[0]["error_message"] is not None
```

### 9.2 Tests de Performance

```python
def test_bulk_insert_performance():
    """Verify DB can handle 1000 inserts."""
    history = PromptHistory(":memory:")

    start = time.time()
    for i in range(1000):
        history.log_prompt({
            "input_text": f"test {i}",
            "output_text": f"output {i}",
            "success": True
        })
    elapsed = time.time() - start

    # Should be < 1 second for 1000 inserts
    assert elapsed < 1.0
```

---

## 10. Alternativas Consideradas

### 10.1 No Persistir (Status Quo)

**Ventajas:**
- âœ… Zero complejidad
- âœ… Zero storage overhead
- âœ… Maximum privacy

**Desventajas:**
- âŒ Imposible analizar uso
- âŒ Imposible debuggear
- âŒ Imposible mejorar

**Veredicto:** No es viable a largo plazo

### 10.2 Cloud Storage

**No considerado** por:
- ViolaciÃ³n de principio "local-first"
- Costos de infraestructura
- Latencia de red
- Privacy concerns

---

## 11. Roadmap de DecisiÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DECISION TREE                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Â¿Necesitas buscar prompts semÃ¡nticamente?
â”‚
â”œâ”€ NO â†’ Usar SQLite (recomendado)
â”‚        â”‚
â”‚        â””â”€ Â¿Necesitas anÃ¡lisis complejo?
â”‚             â”œâ”€ SÃ â†’ SQLite + queries SQL
â”‚             â””â”€ NO â†’ SQLite bÃ¡sico
â”‚
â””â”€ SÃ â†’ Vector DB (Chroma, FAISS, etc.)
          (Futuro - cuando haya 10k+ prompts)
```

**RecomendaciÃ³n actual:** SQLite MVP

---

## 12. ConclusiÃ³n

**Estado:** ğŸ”´ Sin implementar

**Impacto:**
- **Actual:** Medio - sistema funciona pero "ciego"
- **Futuro:** Alto - imposibilita anÃ¡lisis y mejora

**ResoluciÃ³n:** Compleja pero manejable
- Implementar SQLite MVP (1-2 dÃ­as)
- Agregar endpoints de analytics (1 dÃ­a)
- Considerar privacy desde el inicio

**Prioridad:** Alta
- Bloquea anÃ¡lisis de uso
- Bloquea debugging post-mortem
- Bloquea mediciÃ³n de mejora continua

**Beneficios de implementar:**
1. âœ… Visibilidad total del uso
2. âœ… Capacity para debugging
3. âœ… Data-driven improvements
4. âœ… AuditorÃ­a de actividad

---

**Reportado por:** AuditorÃ­a de Pipeline
**Revisado por:** Pendiente
**Aprobado por:** Pendiente
**Fecha de revisiÃ³n:** Pendiente
