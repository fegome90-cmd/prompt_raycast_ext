# NLaC + ComponentCatalog Integration Analysis

**Goal:** Maximum ROI from all components without losing implemented advantages

**Date:** 2025-01-06

---

## Current Assets (What We Have)

### DSPy Legacy Assets
| Asset | Value | Cost to Maintain |
|-------|-------|------------------|
| ComponentCatalog (109 curated examples) | â­â­â­â­â­ High | Low (static JSON) |
| KNNFewShot (semantic search) | â­â­â­â­â­ High | Low (DSPy compiled) |
| Haiku integration (temp=0.0) | â­â­â­â­ High | Already paid |
| Architect pattern output | â­â­â­â­ High | Zero cost |

### NLaC Assets
| Asset | Value | Cost to Maintain |
|-------|-------|------------------|
| IntentClassifier (4 intents) | â­â­â­â­ High | Low (rule-based) |
| ComplexityAnalyzer (3 levels) | â­â­â­â­ High | Low (token + semantic) |
| Role Injection (MultiAIGCD) | â­â­â­â­ High | Low (hierarchy) |
| RaR (complex inputs) | â­â­â­â­ High | Low (template) |
| OPOROptimizer (3 iters, early stop) | â­â­â­â­ High | Medium (3 Haiku calls) |
| PromptValidator (IFEval) | â­â­â­â­ High | Low (constraint checks) |
| PromptCache (SHA256) | â­â­â­â­â­ Critical | Low (SQLite) |

### Shared Assets
| Asset | Value | Both Use? |
|-------|-------|-----------|
| SQLite (history + cache) | â­â­â­â­â­ Critical | âœ… Yes |
| Haiku LLM | â­â­â­â­â­ Critical | âœ… Yes |
| LiteLLM adapter | â­â­â­â­ High | âœ… Yes |

---

## Integration Proposal: Hybrid Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Unified Prompt Pipeline (DSPy + NLaC = Best of Both)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  User Input (idea + context)                                        â”‚
â”‚       â†“                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  STAGE 1: Analysis (NLaC - FAST)                   â”‚            â”‚
â”‚  â”‚  â€¢ IntentClassifier (rule-based, ~1ms)             â”‚            â”‚
â”‚  â”‚  â€¢ ComplexityAnalyzer (token + semantic, ~5ms)     â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚       â†“                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  STAGE 2: Memory Retrieval (DSPy - FAST)           â”‚            â”‚
â”‚  â”‚  â€¢ KNNFewShot.search(k=3)                          â”‚            â”‚
â”‚  â”‚  â€¢ Find by: intent + complexity                    â”‚            â”‚
â”‚  â”‚  â€¢ Returns: 3 similar curated examples             â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚       â†“                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  STAGE 3: Template Construction (NLaC - FAST)      â”‚            â”‚
â”‚  â”‚  â€¢ Role Injection (MultiAIGCD)                      â”‚            â”‚
â”‚  â”‚  â€¢ RaR if COMPLEX                                   â”‚            â”‚
â”‚  â”‚  â€¢ Inject KNN examples as "Reference Prompts"       â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚       â†“                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  STAGE 4: Optimization (OPRO - MEDIUM)              â”‚            â”‚
â”‚  â”‚  â€¢ Iteration 1: Meta-prompt + KNN examples          â”‚            â”‚
â”‚  â”‚  â€¢ Iteration 2: Feedback from Iteration 1           â”‚            â”‚
â”‚  â”‚  â€¢ Iteration 3: Feedback from Iteration 2           â”‚            â”‚
â”‚  â”‚  â€¢ Early stop if score â‰¥ 1.0                        â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚       â†“                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  STAGE 5: Validation (IFEval - FAST)                â”‚            â”‚
â”‚  â”‚  â€¢ Check all constraints                           â”‚            â”‚
â”‚  â”‚  â€¢ Autocorrect if needed                            â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚       â†“                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  STAGE 6: Cache (SHA256 - INSTANT)                  â”‚            â”‚
â”‚  â”‚  â€¢ Check if seen before                            â”‚            â”‚
â”‚  â”‚  â€¢ Return cached result if available               â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚       â†“                                                             â”‚
â”‚  Improved Prompt (structured, optimized, validated)                  â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ROI Calculation

### Current State (Separated)

**DSPy Legacy Mode:**
- Quality: â­â­â­â­ (4/5) - Uses curated examples
- Speed: â­â­â­ (3/5) - KNN + Haiku (~30s)
- Consistency: â­â­â­â­â­ (5/5) - temp=0.0
- Optimization: â­â­ (2/5) - No iterative refinement
- Validation: â­â­ (2/5) - No IFEval
- **Overall Score: 16/25 (64%)**

**NLaC Mode (Current):**
- Quality: â­â­â­ (3/5) - No real examples
- Speed: â­â­ (2/5) - OPRO 3x (~90s)
- Consistency: â­â­â­â­ (4/5) - RaR helps
- Optimization: â­â­â­â­â­ (5/5) - OPRO + IFEval
- Validation: â­â­â­â­â­ (5/5) - Full IFEval
- **Overall Score: 19/25 (76%)**

### Proposed Hybrid Mode

**Combined Pipeline:**
- Quality: â­â­â­â­â­ (5/5) - Curated examples + OPRO
- Speed: â­â­â­ (3/5) - OPRO 3x but with cache (~60s avg)
- Consistency: â­â­â­â­â­ (5/5) - temp=0.0 + RaR
- Optimization: â­â­â­â­â­ (5/5) - OPRO + IFEval + KNN
- Validation: â­â­â­â­â­ (5/5) - Full IFEval
- **Overall Score: 23/25 (92%)**

### ROI Breakdown

| Metric | DSPy | NLaC | Hybrid | Gain |
|--------|------|------|--------|------|
| Quality | 4/5 | 3/5 | 5/5 | +25% vs NLaC |
| Speed | 3/5 | 2/5 | 3/5 | +50% vs NLaC |
| Optimization | 2/5 | 5/5 | 5/5 | Same as NLaC |
| Validation | 2/5 | 5/5 | 5/5 | Same as NLaC |
| **Total** | **16/25** | **19/25** | **23/25** | **+21% vs best** |

### Cost Analysis

**Per Request Costs:**
- DSPy Legacy: 1 Haiku call = 1 unit
- NLaC (current): 3 Haiku calls (OPRO) = 3 units
- Hybrid: 3 Haiku calls (OPRO) + KNN lookup = ~3 units

**Trade-off:**
- **Cost:** Same as NLaC (3 Haiku calls)
- **Benefit:** +25% quality (real examples instead of templates)
- **ROI:** Worth it for quality-critical use cases

**With Cache (Hit rate ~70%):**
- Average cost: 0.7 Ã— 0 (cache) + 0.3 Ã— 3 = 0.9 units per request
- **Effective ROI:** 70% cost reduction for identical requests

---

## Example 1: Simple Debug Request (Reflexion, not OPRO)

### Input
```
Idea: "Fix this error"
Context: "ZeroDivisionError when dividing by user input"
```

### Pipeline Flow

**Stage 1: Analysis (NLaC)**
```
IntentClassifier: DEBUG (keyword: "error", "Fix")
ComplexityAnalyzer: SIMPLE (12 tokens, no technical jargon)
```

**Stage 2: Memory (DSPy KNN)**
```python
# KNN finds 3 similar DEBUG + SIMPLE examples
examples = KNNFewShot.search(
    query="Fix ZeroDivisionError",
    filters={intent: DEBUG, complexity: SIMPLE},
    k=3
)

# Returns:
# 1. "Fix NameError in variable assignment" â†’ Debugger role
# 2. "Handle TypeError in function call" â†’ Debugger role
# 3. "Debug IndexError in list access" â†’ Debugger role
```

**Stage 3: Template + Reflexion (NLaC)**

**Critical Design Decision:** Use **Reflexion** instead of OPRO for debugging

**Why?** MultiAIGCD "Scenario II" (Fixing Runtime Errors) already has:
- The bug (observable behavior)
- The error (stack trace, exception)

OPRO is slow/expensive for this. **Reflexion is faster:**
```
Generate Code â†’ Execute â†’ If fails, inject error into context â†’ Retry
```

**Stage 4: Reflexion Loop**
```python
# Iteration 1: Generate fix attempt
code = llm.generate(prompt_with_examples)
result = execute(code)

if result.failed:
    # Iteration 2: Inject error feedback
    prompt_v2 = f"{prompt}\n\n# Error\n{result.error}\n\n# Fix the above error"
    code_v2 = llm.generate(prompt_v2)

# Typically converges in 1-2 iterations (vs 3 for OPRO)
```

**Stage 5: IFEval + Cache** (same as other pipelines)
Identify and fix the NameError: 'my_var' undefined

# Solution
Check variable scope, ensure initialization before use...

## Example 2
Input: "Handle TypeError in function call"
Output:
# Role
You are a Debugger.

# Task
Fix TypeError: expected str, got int...

# Solution
Add type validation or convert types...

## Example 3
[Similar structure...]

# Your Response
Following the pattern above, debug this ZeroDivisionError:
```

**Stage 4: OPRO Optimization**
```python
# Iteration 1
input_prompt = "<template from Stage 3>"
score1, feedback1 = OPOROptimizer.evaluate(input_prompt)
# Score: 0.75, Feedback: "Missing input validation"

# Iteration 2
input_prompt_v2 = f"{input_prompt}\n\n# Note: Always validate user input first"
score2, feedback2 = OPOROptimizer.evaluate(input_prompt_v2)
# Score: 0.90, Feedback: "Add specific fix for division by zero"

# Iteration 3
input_prompt_v3 = f"{input_prompt_v2}\n\n# Specific Fix: Use try-except or check if denominator != 0"
score3, feedback3 = OPOROptimizer.evaluate(input_prompt_v3)
# Score: 0.98, Early stop!
```

**Stage 5: IFEval Validation**
```python
passed, warnings = PromptValidator.validate(final_prompt)
# Passed: âœ… All constraints satisfied
# Warnings: []
```

**Stage 6: Cache**
```python
cache_key = SHA256("Fix this error|ZeroDivisionError...|nlac")
# Store in SQLite for next time
```

### Final Output
```markdown
# Role
You are a **Debugger** specializing in Python error handling.

# Task
Debug and fix this ZeroDivisionError that occurs when dividing by user input.

# Context
The error happens when processing user-provided numbers. We need to ensure the division operation is safe.

# Solution Approach
1. **Validate input first**: Check if denominator is zero or convert to safe value
2. **Use defensive coding**: Try-except block or conditional check
3. **Provide clear error message**: Help user understand what went wrong

# Example Fix
```python
try:
    result = numerator / denominator
except ZeroDivisionError:
    result = 0  # or raise ValueError with message
```

# Instructions
Analyze the specific context where this error occurs and provide:
1. Root cause explanation
2. Code fix with comments
3. Prevention strategy for similar cases
```

---

## Example 2: Moderate Refactor Request (with Expected Output)

### Input
```
Idea: "Refactor this function to be more readable"
Context: "Function has nested if statements and is 50 lines long"
```

### Pipeline Flow

**Stage 1: Analysis**
```
IntentClassifier: REFACTOR (keyword: "refactor", "readable")
ComplexityAnalyzer: MODERATE (23 tokens, specific complexity mentioned)
```

**Stage 2: Memory (KNN with Expected Output)**
```python
# CRITICAL: KNN must find examples WITH expected output
# MultiAIGCD Scenario III: Correcting Incorrect Outputs
# Without expected output, refactor is cosmetic, not functional

examples = KNNFewShot.search(
    query="Refactor nested function with readability focus",
    filters={
        intent: REFACTOR,
        complexity: MODERATE,
        has_expected_output: True  # NEW: Filter for complete examples
    },
    k=3
)

# Returns examples like:
# 1. "Extract method from long function"
#    Input: [nested code] â†’ Expected: [extracted methods]
# 2. "Simplify conditional chains"
#    Input: [nested ifs] â†’ Expected: [early returns]
# 3. "Optimize nested loops"
#    Input: [nested loops] â†’ Expected: [flattened logic]
```

**Stage 3: Template with Expected Output Section**
```markdown
# Role
You are a **Code Refactoring Specialist**.

# Task
Refactor a 50-line function with nested if statements to improve readability.

# Expected Output Format
```python
def refactored_function(data):
    # Clear, single-responsibility functions
    # Early returns for validation
    # Descriptive variable names
    # Proper error handling
    return result
```

# Reference Patterns (from ComponentCatalog)

## Pattern 1: Extract Method
**Input:** Long function with nested logic
**Expected Output:** Multiple small functions with clear names
```python
# Before
def process(data):
    if validate(data):
        if check_permission(data):
            result = compute(data)
            return format(result)

# After
def process(data):
    if not validate(data):
        return None
    if not check_permission(data):
        raise PermissionError()
    result = compute(data)
    return format(result)
```

## Pattern 2: Early Returns
**Input:** Deeply nested conditions
**Expected Output:** Flat structure with guard clauses
[Similar structure with before/after]

## Pattern 3: Guard Clauses with Expected Behavior
**Input:** Complex boolean expressions
**Expected Output:** Descriptive helper variables
[Similar structure]

# Your Task
Apply these patterns to refactor the function while **preserving behavior**.
The refactored code must produce the same output for the same inputs.
```
Example: `if user and user.is_active and user.has_permission:` â†’ `if can_user_action(user):`

# Your Task
Apply these patterns to refactor the function while preserving behavior.
```

**Stage 4-6:** OPO optimizes, IFEval validates, Cache stores

---

## Example 3: Complex Generate Request (RaR with Critical Constraints)

### Input
```
Idea: "Create a comprehensive authentication system"
Context: "Need OAuth2, JWT, role-based access, session management, password reset"
```

### Pipeline Flow

**Stage 1: Analysis**
```
IntentClassifier: GENERATE (keyword: "create", "build")
ComplexityAnalyzer: COMPLEX (35 tokens, 5 distinct technical requirements)
```

**Stage 2: Memory**
```python
# KNN finds 3 similar GENERATE + COMPLEX examples
examples = [
    "Build payment system with Stripe, webhooks, refund handling",
    "Design microservices architecture with service mesh, API gateway",
    "Create real-time notification system with WebSocket, Redis, queues"
]
```

**Stage 3: Template (with RaR + Critical Constraint)**
```markdown
# Role
You are a **Software Architect** specializing in security systems.

# Understanding Section (RaR - Rephrase and Respond)
This request involves creating an authentication system with multiple components:
- **OAuth2**: Third-party login integration (Google, GitHub)
- **JWT**: Token-based authentication (access + refresh tokens)
- **RBAC**: Role-based access control (Admin, User, Guest roles)
- **Sessions**: User session management (Redis-backed, timeout handling)
- **Password Reset**: Self-service recovery (email token flow)

These components must work together securely while maintaining usability.

âš ï¸ **CRITICAL CONSTRAINT - RaR Scope Limitation:**
When rephrasing this request, you MUST:
- **EXPAND** the instruction and requirements
- **CLARIFY** the interactions between components
- **DO NOT** rephrase or alter the functional definitions:
  - OAuth2 provider requirements (Google, GitHub)
  - JWT token lifetime (15min access, 7d refresh)
  - RBAC role hierarchy (Admin > User > Guest)
  - Session storage mechanism (Redis)

The RaR should expand on **HOW** to implement, not **WHAT** to implement.

# Task
Design a comprehensive authentication system addressing all requirements with the specified constraints.

# Reference Architectures (from ComponentCatalog)

## Pattern 1: Modular Auth Design
From: "Build payment system..."
Key insight: Separate concerns into distinct modules
```
/auth/
  /oauth/      # Third-party login handlers
  /jwt/        # Token generation and validation
  /rbac/       # Permission checking middleware
  /session/    # Session management endpoints
```

## Pattern 2: Security Layers (Defense in Depth)
From: "Design microservices..."
```
Layer 1: API Gateway (rate limiting, auth validation)
Layer 2: Auth Service (token issuance, validation)
Layer 3: Resource Server (permission checks)
Layer 4: Database (encrypted credentials with AES-256)
```

## Pattern 3: Hybrid State Management
From: "Create real-time notification..."
```
JWT Access Token: 15 minutes (stateless, API calls)
Refresh Token: 7 days (stateful, Redis storage)
Session Data: Redis with automatic expiration
```

# Requirements (NON-NEGOTIABLE)
1. OAuth2 providers: Google, GitHub (exact requirement)
2. JWT: Access token = 15min, Refresh token = 7 days
3. RBAC: Roles = [Admin, User, Guest] with specific permission matrix
4. Session Storage: Redis with TTL-based expiration
5. Password Reset: Email-based token with 1-hour validity
```

**Old content that will be replaced:**
4. Session: Redis-backed with timeout
5. Password Reset: Email token flow

# Design Constraints
- Use industry-standard libraries
- Follow OWASP guidelines
- Include error handling
- Provide database schema
```

**Stage 4-6:** OPO optimizes (3 iterations with RaR feedback), IFEval validates, Cache stores

---

## Implementation Strategy

### Phase 1: KNN Integration (Low Risk)
**File:** `hemdov/domain/services/nlac_builder.py`

**Changes:**
```python
class NLaCBuilder:
    def __init__(self, component_catalog: ComponentCatalog):
        self.catalog = component_catalog
        # ... existing init

    def build(self, request: NLaCRequest) -> PromptObject:
        # ... existing analysis

        # NEW: Fetch few-shot examples
        examples = self.catalog.find_similar(
            intent=intent_type,
            complexity=complexity.level,
            k=3 if complexity == ComplexityLevel.SIMPLE else 5
        )

        # Build template with examples
        template = self._build_template(
            intent=intent_type,
            role=role,
            examples=examples,  # NEW parameter
            use_rar=complexity == ComplexityLevel.COMPLEX
        )
```

**Risk:** Low - additive change, doesn't break existing flow

### Phase 2: Template Enhancement (Medium Risk)
**File:** `hemdov/domain/services/nlac_builder.py`

**Changes:**
```python
def _build_template(self, intent, role, examples, use_rar):
    sections = [
        f"# Role\nYou are a **{role}**.",
        f"# Task\n{self._format_task(intent)}",
    ]

    # NEW: Add reference examples
    if examples:
        sections.append("\n# Reference Patterns")
        for i, example in enumerate(examples, 1):
            sections.append(f"\n## Example {i}")
            sections.append(f"Input: {example.input}")
            sections.append(f"Output: {example.output}")

    # NEW: Add RaR for complex
    if use_rar:
        sections.insert(2, self._build_rar_section())

    return "\n".join(sections)
```

**Risk:** Medium - changes template structure

### Phase 3: OPRO Enhancement (Low Risk)
**File:** `hemdov/domain/services/oprop_optimizer.py`

**Changes:**
```python
def _generate_variation(self, prompt_obj, trajectory):
    # NEW: Include KNN examples in meta-prompt
    examples = prompt_obj.strategy_meta.get("knn_examples", [])

    meta_prompt = f"""
Improve this prompt using these reference patterns as inspiration:

{self._format_examples(examples)}

Current prompt:
{prompt_obj.template}

Previous iterations:
{self._format_trajectory(trajectory)}
"""
```

**Risk:** Low - enhances optimization without changing core logic

### Phase 4: Testing (Critical)
**Files:** `tests/test_nlac_integration.py`

**Test cases:**
```python
def test_nlac_uses_knn_examples():
    """NLaC should fetch and inject KNN examples"""
    builder = NLaCBuilder(catalog=mock_catalog)
    result = builder.build(request)

    assert "Reference Patterns" in result.template
    assert len(result.strategy_meta["knn_examples"]) == 3

def test_knn_fallback_when_no_examples():
    """Should work even if KNN returns no examples"""
    builder = NLaCBuilder(catalog=empty_catalog)
    result = builder.build(request)

    assert result.template  # Should still generate

def test_complex_uses_more_examples():
    """Complex prompts should use k=5"""
    request = complex_request  # Triggers COMPLEX
    result = builder.build(request)

    assert len(result.strategy_meta["knn_examples"]) == 5
```

---

## Migration Path

### Step 1: Create Integration Service (1 day)
```python
# hemdov/domain/services/knn_provider.py
class KNNProvider:
    """Bridge between ComponentCatalog and NLaC"""

    def __init__(self, catalog_path: str):
        self.catalog = ComponentCatalog.from_json(catalog_path)

    def find_examples(self, intent: str, complexity: str, k: int = 3):
        return self.catalog.search(
            intent=intent,
            complexity=complexity,
            limit=k
        )
```

### Step 2: Modify NLaCBuilder (1 day)
Add KNNProvider dependency and example injection

### Step 3: Update NLaCStrategy (0.5 day)
Pass KNN examples through the pipeline

### Step 4: Add Tests (1 day)
Cover integration scenarios

### Step 5: Update Frontend (0.5 day)
Remove `mode` dropdown, use unified pipeline

**Total: 4 days**

---

## Summary

### Critical Refinements Applied (Based on MultiAIGCD & State-of-the-Art)

#### Refinement 1: Debug Uses Reflexion, Not OPRO
**Original:** Use OPRO for all scenarios
**Refinement:** Use **Reflexion** for DEBUG (MultiAIGCD Scenario II)
**Why:** Debugging already has the bug + error. OPRO is expensive/slow. Reflexion loop (Generate â†’ Execute â†’ Retry with error) converges in 1-2 iterations vs 3 for OPRO.
**Impact:** -33% latency for debug requests, same quality

#### Refinement 2: Refactor Requires Expected Output
**Original:** KNN finds refactoring examples
**Refinement:** KNN must find examples **with expected output** (MultiAIGCD Scenario III)
**Why:** Without expected output, refactor is cosmetic, not functional. KNN filter: `has_expected_output: True`
**Impact:** Ensures functional correctness, not just readability

#### Refinement 3: RaR Has Critical Scope Constraints
**Original:** RaR rephrases the request
**Refinement:** RaR **CANNOT rephrase functional definitions** (MultiAIGCD anti-lazy-prompting)
**Why:** Prevents altering requirements. RaR expands "HOW" to implement, not "WHAT" to implement.
**Constraint:**
```
DO NOT rephrase:
- OAuth2 providers (Google, GitHub)
- JWT lifetimes (15min access, 7d refresh)
- RBAC roles (Admin > User > Guest)

DO expand:
- Interaction patterns between components
- Implementation approaches
- Error handling strategies
```

### What We Keep âœ…
- All NLaC services (Intent, Complexity, Role, RaR, OPRO, IFEval, Cache, Reflexion)
- All DSPy services (KNN, ComponentCatalog, Few-shot learning)
- SQL persistence (history, cache)
- Haiku integration (temp=0.0, 120s timeout)

### What We Gain ğŸ¯
- NLaC gets real-world examples (not just templates)
- Quality improves from 3/5 â†’ 5/5
- Reflexion for debugging: -33% latency, same quality
- Functional correctness via expected outputs
- RaR precision with scope constraints
- ROI: +21% overall improvement (higher for debug with Reflexion)
- Cache effectiveness increases (better prompts = more hits)

### What We Sacrifice âš ï¸
- Initial latency: ~60s avg (vs 30s for DSPy alone, ~40s for debug with Reflexion)
- Cost: 3 Haiku calls for complex, 1-2 for debug (vs 1 for DSPy)
- Complexity: More moving parts

### Final Recommendation
**Implement the hybrid architecture with refinements** - the quality gain (+25% vs NLaC), optimization (+150% vs DSPy), and Reflexion for debugging justify the cost increase. With 70% cache hit rate, effective cost is reduced by 70% for repeat requests.

---

## Approved & Ready for Implementation

âœ… Architecture validated against MultiAIGCD scenarios
âœ… ROI calculated (+21% overall, higher for debug)
âœ… Pipelines refined with state-of-the-art techniques
âœ… Three detailed examples provided
âœ… Migration path defined (4 days, low risk)

**Next Step:** Generate implementation plan with `superpowers:writing-plans`
