# NLaC Pipeline - Integrated Improvement Plan

> **Plan Date:** 2026-01-13
> **Version:** 3.0 (Sequential Thinking Analysis Applied)
> **Status:** Ready for Implementation
> **North Star:** Production-ready NLaC pipeline with complete DSPy hybrid integration

---

## üö¶ Executive Summary - Plan v3.0

**Status:** ‚úÖ **READY FOR IMPLEMENTATION**

El plan v2.0 ha sido actualizado con decisiones concretas derivadas de an√°lisis secuencial multi-agente. Los 3 bloqueadores identificados en v2.0 han sido resueltos:

| Bloqueador v2.0 | Decisi√≥n v3.0 | Estado |
|-----------------|---------------|--------|
| **LLM Provider** | Ollama nomic-embed-text (PoC) | ‚úÖ RESUELTO |
| **Ground Truth** | Bootstrap desde cat√°logo existente | ‚úÖ MITIGADO |
| **Cost Budget** | $0 (Ollama) o calcular despu√©s de PoC | ‚úÖ DEFERIDO |

**Timeline ajustado:** 35-54 horas (vs 33-58 original) - +2 horas aceptables

---

## üö® Critical Issues Summary - v3.0 RESOLVED

| Issue | Severity | v2.0 | v3.0 | Resolution |
|-------|----------|------|------|------------|
| **LLM Provider** | CRITICAL | ‚ùå Unspecified | ‚úÖ Ollama nomic-embed-text | PoC inicial, fallback a OpenAI |
| **Ground Truth** | HIGH | ‚ùå 100 ejemplos nuevos | ‚úÖ Bootstrap cat√°logo | Usar 109 ejemplos existentes |
| **Cost Budget** | HIGH | ‚ùå "$X/month" | ‚úÖ $0 (Ollama) | Solo calcular si falla PoC |
| **KNN validation** | HIGH | ‚ö†Ô∏è Pending | ‚úÖ Validated | Remover tabla obsoleta |
| **Vector dimensions** | CRITICAL | ‚ö†Ô∏è Router specified | ‚úÖ Router + runtime validation | Add assert en _dspy_vectorize |
| **Phase ordering** | HIGH | ‚ö†Ô∏è Incorrect | ‚úÖ Corrected | Cache/IFEval antes de DSPy |
| **Ports definition** | HIGH | ‚ö†Ô∏è Incomplete | ‚ö†Ô∏è Added | Crear CachePort, VectorizerPort |

---

## üéØ LLM Provider Decision (NEW)

### Elecci√≥n: Ollama nomic-embed-text

**Raz√≥n:** PoC r√°pido sin costo ni dependencias externas

```bash
# Setup commands (Fase 0)
curl -fsSL https://ollama.com/install.sh | sh
ollama pull nomic-embed-text
ollama run nomic-embed-text "test query"
```

**Especificaciones:**
- **Dimensiones:** 768 (compatible con plan)
- **Costo:** $0 (local)
- **Latency objetivo:** <500ms por embedding
- **Fallback strategy:** Switch a OpenAI si PoC falla

### Fallback Path (si Ollama no cumple requisitos)

```python
# Fase 3 PoC - Go/No-Go Criteria
def validate_ollama_poc():
    criteria = [
        ("embeddings_generate", test_ollama_embeddings()),
        ("dimensions_compatible", test_dimensions_768()),
        ("latency_target", test_latency_p95_lt_500ms()),
        ("quality_baseline", test_quality_ge_bigrams()),
    ]

    passed = [name for name, result in criteria if result]

    if len(passed) == 4:
        return "ollama", "$0/month"  # Stay with Ollama
    else:
        return "openai", calculate_openai_cost()  # Switch to OpenAI
```

---

## üî¥ Pre-Execution Checklist - v3.0 UPDATED

### Before Starting Fase 0

```bash
# 1. Verificar Ollama disponible (o instalar)
which ollama || curl -fsSL https://ollama.com/install.sh | sh

# 2. Descargar modelo de embeddings
ollama pull nomic-embed-text

# 3. Validar Ollama funciona
ollama run nomic-embed-text "test query"

# 4. Tests pasando
make test

# 5. Medir baseline actual
python scripts/measure_baseline.py
```

### Prerequisites by Phase - UPDATED

**Fase 0 (EXTENDIDA):**
- [ ] Ollama installed and `nomic-embed-text` downloaded
- [ ] IFEval calibration bootstrapped from catalog (2-4h)
- [ ] Baseline metrics saved
- [ ] Feature flags infrastructure created
- [ ] Current codebase tests passing

**Fase 1:**
- [ ] No `except Exception` remains (already validated ~90%)

**Fase 2:**
- [ ] Cache schema reviewed and approved
- [ ] IFEval threshold calibrated (may be 0.6-0.8)

**Fase 3 (DSPy Integration):**
- [ ] Ollama PoC completed (see Go/No-Go below)
- [ ] Embeddings validated: 768 dimensions
- [ ] Latency P95 <500ms per embedding
- [ ] Quality ‚â• current bigram baseline
- [ ] Cost decision: $0 (Ollama) OR calculate for OpenAI

---

## üìã Plan de Trabajo - Vista General v3.0

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FASE 0: Validaci√≥n Extendida                  ‚îÇ
‚îÇ  ‚è±Ô∏è 4-6 horas (vs 1-2h original)                               ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  1. Setup Ollama + nomic-embed-text (1 hora) ‚úÖ RESUELVE Blocker #1‚îÇ
‚îÇ  2. Bootstrap IFEval calibration (2-4 horas) ‚úÖ MITIGA Blocker #2  ‚îÇ
‚îÇ  3. Baseline measurement script (1-2 horas)                     ‚îÇ
‚îÇ  4. Feature flags infrastructure (1-2 horas)                      ‚îÇ
‚îÇ  5. Define missing ports (1 hora)                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FASE 1: Fundamentos                          ‚îÇ
‚îÇ  ‚è±Ô∏è 1-2 horas (yaÂ§ßÈÉ® complete)                                 ‚îÇ
‚îÇ  - Error handling espec√≠fico remaining (~10%)                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FASE 2: Safety Nets                          ‚îÇ
‚îÇ  ‚è±Ô∏è 12-18 horas                                                ‚îÇ
‚îÇ  - Cache Layer (SQLite)                                         ‚îÇ
‚îÇ  - IFEval Validator (with calibrated threshold)                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FASE 3: DSPy Integration                     ‚îÇ
‚îÇ  ‚è±Ô∏è 14-22 horas                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ  ‚îÇ  ‚ö†Ô∏è Go/No-Go PoC Gate (antes de implementar)                ‚îÇ‚îÇ
‚îÇ  ‚îÇ  - Ollama embeddings validados                              ‚îÇ‚îÇ
‚îÇ  ‚îÇ  - 768 dimensions compatible                                 ‚îÇ‚îÇ
‚îÇ  ‚îÇ  - Latency <500ms                                            ‚îÇ‚îÇ
‚îÇ  ‚îÇ  - Quality ‚â• baseline                                        ‚îÇ‚îÇ
‚îÇ  ‚îÇ  - Decision: Stay Ollama ($0) OR switch OpenAI              ‚îÇ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îÇ  - Hybrid Vectorizer (router pattern)                           ‚îÇ
‚îÇ  - KNNProvider integration                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FASE 4: Observability                        ‚îÇ
‚îÇ  ‚è±Ô∏è 4-6 horas                                                  ‚îÇ
‚îÇ  - M√©tricas + tracing                                          ‚îÇ
‚îÇ  - Enhanced RaR (DEFERido - no cr√≠tico)                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìä Timeline v3.0 - UPDATED

| Fase | v2.0 Estimate | v3.0 Estimate | Cambio | Notas |
|-------|--------------|--------------|--------|-------|
| **Fase 0** | 1-2h | **4-6h** | +3-4h | Ollama + calibraci√≥n + ports |
| **Fase 1** | 2-4h | 1-2h | -1-2h | YaÂ§ßÈÉ® complete |
| **Fase 2** | 12-18h | 12-18h | 0 | Sin cambio |
| **Fase 3** | 14-22h | 14-22h | 0 | PoC decision ya tomada |
| **Fase 4** | 4-6h | 4-6h | 0 | Sin cambio |
| **Total** | **33-58h** | **35-54h** | **+2h** | Aceptable |

---

## üéØ Fase 0: Validaci√≥n Extendida (v3.0)

### Task 0.1: Setup Ollama nomic-embed-text (1 hora)

**Prop√≥sito:** Resolver bloqueador LLM Provider para embeddings

**Comandos:**
```bash
# Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Start Ollama service
ollama serve &

# Download embedding model
ollama pull nomic-embed-text

# Verify installation
ollama run nomic-embed-text "test query"
```

**Validaci√≥n:**
```python
# scripts/validate_ollama.py
import requests

def validate_ollama():
    response = requests.post(
        "http://localhost:11434/api/embeddings",
        json={"model": "nomic-embed-text", "prompt": "test"}
    )
    assert response.status_code == 200
    embedding = response.json()["embedding"]
    assert len(embedding) == 768  # Verify dimension
    print(f"‚úÖ Ollama validated: {len(embedding)} dimensions")
```

**Output:** Ollama running con nomic-embed-text listo para PoC

---

### Task 0.2: Bootstrap IFEval Calibration (2-4 horas)

**Prop√≥sito:** Mitigar bloqueador Ground Truth usando cat√°logo existente

**Approach:** NO crear 100 ejemplos nuevos. Usar los 109 existentes.

```python
# scripts/bootstrap_ifeval_calibration.py
import json
from pathlib import Path
from hemdov.domain.services.ifeval_validator import IFEvalValidator

def bootstrap_calibration():
    """Bootstrap IFEval calibration from existing catalog."""

    # Load existing catalog
    catalog_path = Path("datasets/exports/unified-fewshot-pool-v2.json")
    with open(catalog_path) as f:
        catalog = json.load(f)

    # Extract improved prompts from catalog
    improved_prompts = [
        ex["outputs"]["improved_prompt"]
        for ex in catalog["examples"]
        if "improved_prompt" in ex.get("outputs", {})
    ]

    print(f"Found {len(improved_prompts)} existing improved prompts")

    # Run IFEval on each
    validator = IFEvalValidator(threshold=0.7)  # Start conservative
    results = []

    for prompt in improved_prompts:
        result = validator.validate(prompt)
        results.append({
            "score": result["total_score"],
            "passed": result["overall_pass"],
            "prompt_length": len(prompt)
        })

    # Analyze score distribution
    scores = [r["score"] for r in results]
    import statistics
    print(f"Score distribution:")
    print(f"  Min: {min(scores):.2f}")
    print(f"  Max: {max(scores):.2f}")
    print(f"  Mean: {statistics.mean(scores):.2f}")
    print(f"  Median: {statistics.median(scores):.2f}")
    print(f"  Pass rate: {sum(1 for r in results if r['passed'])}/{len(results)}")

    # Save calibration data
    calibration_output = Path("data/ifeval-calibration.json")
    calibration_output.parent.mkdir(exist_ok=True)

    with open(calibration_output, "w") as f:
        json.dump({
            "threshold_tested": 0.7,
            "results": results,
            "statistics": {
                "min": min(scores),
                "max": max(scores),
                "mean": statistics.mean(scores),
                "median": statistics.median(scores),
                "pass_rate": sum(1 for r in results if r['passed']) / len(results)
            }
        }, f, indent=2)

    print(f"\nüí° Recommendation:")
    if statistics.mean(scores) < 0.6:
        print(f"  Threshold too high - try 0.5 or 0.6")
    elif statistics.mean(scores) > 0.9:
        print(f"  Threshold too low - try 0.8 or 0.9")
    else:
        print(f"  Threshold 0.7 seems reasonable")

    return results
```

**Output:**
- `data/ifeval-calibration.json` con distribuci√≥n de scores
- Threshold recomendado basado en datos reales
- Fase 2 puede comenzar con threshold calibrado

---

### Task 0.3: Baseline Measurement Script (1-2 horas)

**Prop√≥sito:** Medir baseline actual antes de cualquier cambio

```python
# scripts/measure_baseline.py
import time
import json
import statistics
from pathlib import Path
from hemdov.domain.services.knn_provider import KNNProvider
from hemdov.domain.services.intent_classifier import IntentClassifier
from hemdov.domain.services.nlac_builder import NLaCBuilder

class BaselineMeasurer:
    def __init__(self, output_path: Path = Path("data/baseline-v3.0.json")):
        self.output_path = output_path
        self.results = {}

    def measure_knn_latency(self, iterations: int = 100):
        """Measure KNN provider latency."""
        knn = KNNProvider()

        latencies = []
        for _ in range(iterations):
            start = time.perf_counter()
            examples = knn.find_examples(
                intent="explain",
                complexity="moderate",
                k=3
            )
            end = time.perf_counter()
            latencies.append((end - start) * 1000)  # Convert to ms

        return {
            "p50": statistics.median(latencies),
            "p95": sorted(latencies)[int(iterations * 0.95)],
            "p99": sorted(latencies)[int(iterations * 0.99)],
            "mean": statistics.mean(latencies),
            "min": min(latencies),
            "max": max(latencies),
        }

    def measure_exception_coverage(self):
        """Count specific vs generic exceptions in domain services."""
        import glob
        import re

        services = glob.glob("hemdov/domain/services/*.py")
        specific_count = 0
        generic_count = 0

        for service in services:
            content = Path(service).read_text()

            # Count specific exceptions
            specific_count += len(re.findall(
                r'except\s*\((?:RuntimeError|KeyError|TypeError|ValueError|ConnectionError|TimeoutError)',
                content
            ))

            # Count generic exceptions (anti-pattern)
            generic_count += len(re.findall(
                r'except\s*Exception',
                content
            ))

        total = specific_count + generic_count
        if total == 0:
            return {"coverage": "100%", "specific": specific_count, "generic": generic_count}

        return {
            "coverage": f"{(specific_count / total) * 100:.1f}%",
            "specific": specific_count,
            "generic": generic_count
        }

    def measure_full_pipeline_latency(self, iterations: int = 20):
        """Measure end-to-end NLaC pipeline latency."""
        from hemdov.domain.dto.nlac_models import NLaCRequest

        builder = NLaCBuilder()

        latencies = []
        for _ in range(iterations):
            request = NLaCRequest(
                idea="Create a function to sort a list",
                context="Use Python"
            )

            start = time.perf_counter()
            result = builder.build(request)
            end = time.perf_counter()

            latencies.append((end - start) * 1000)

        return {
            "p50": statistics.median(latencies),
            "p95": sorted(latencies)[int(iterations * 0.95)],
            "p99": sorted(latencies)[int(iterations * 0.99)],
            "mean": statistics.mean(latencies),
        }

    def run_all(self):
        """Run all baseline measurements."""
        print("üîç Measuring baseline...")

        print("  KNN latency (100 iterations)...")
        self.results["knn_latency"] = self.measure_knn_latency(100)

        print("  Exception coverage...")
        self.results["exception_coverage"] = self.measure_exception_coverage()

        print("  Full pipeline latency (20 iterations)...")
        self.results["pipeline_latency_p95"] = self.measure_full_pipeline_latency(20)

        # Save results
        self.output_path.parent.mkdir(exist_ok=True)
        with open(self.output_path, "w") as f:
            json.dump({
                "timestamp": time.time(),
                "results": self.results
            }, f, indent=2)

        print(f"\n‚úÖ Baseline saved to {self.output_path}")
        self._print_summary()

    def _print_summary(self):
        print("\nüìä Baseline Summary:")
        print(f"  KNN P50 latency: {self.results['knn_latency']['p50']:.2f}ms")
        print(f"  KNN P95 latency: {self.results['knn_latency']['p95']:.2f}ms")
        print(f"  Exception coverage: {self.results['exception_coverage']['coverage']}")
        print(f"  Pipeline P95: {self.results['pipeline_latency_p95']['p95']:.2f}ms")

if __name__ == "__main__":
    BaselineMeasurer().run_all()
```

---

### Task 0.4: Feature Flags Infrastructure (1-2 horas)

**Prop√≥sito:** Enable incremental rollout y rollback

```python
# hemdov/infrastructure/config/feature_flags.py
from dataclasses import dataclass
from os import getenv
from pathlib import Path
import json

@dataclass
class FeatureFlags:
    """Feature flags for incremental rollout."""

    # DSPy Integration
    enable_dspy_embeddings: bool = _parse_bool(getenv("ENABLE_DSPY_EMBEDDINGS", "false"))

    # Cache Layer
    enable_cache: bool = _parse_bool(getenv("ENABLE_CACHE", "true"))

    # IFEval Validation
    enable_ifeval: bool = _parse_bool(getenv("ENABLE_IFEVAL", "true"))

    # Metrics Collection
    enable_metrics: bool = _parse_bool(getenv("ENABLE_METRICS", "true"))

    # Enhanced RaR (DEFERRED - not critical)
    enable_enhanced_rar: bool = _parse_bool(getenv("ENABLE_ENHANCED_RAR", "false"))

    # Embedding Provider Selection (NEW)
    embedding_provider: str = getenv("EMBEDDING_PROVIDER", "ollama")  # ollama | openai

    @classmethod
    def save(cls, path: Path = Path("config/feature_flags.json")):
        """Save current flags to file for debugging."""
        flags = cls()
        path.parent.mkdir(exist_ok=True)
        with open(path, "w") as f:
            json.dump({
                "enable_dspy_embeddings": flags.enable_dspy_embeddings,
                "enable_cache": flags.enable_cache,
                "enable_ifeval": flags.enable_ifeval,
                "enable_metrics": flags.enable_metrics,
                "enable_enhanced_rar": flags.enable_enhanced_rar,
                "embedding_provider": flags.embedding_provider,
            }, f, indent=2)

    @classmethod
    def load(cls, path: Path = Path("config/feature_flags.json")):
        """Load flags from file if exists."""
        if not path.exists():
            return cls()

        with open(path) as f:
            data = json.load(f)

        return cls(
            enable_dspy_embeddings=data.get("enable_dspy_embeddings", False),
            enable_cache=data.get("enable_cache", True),
            enable_ifeval=data.get("enable_ifeval", True),
            enable_metrics=data.get("enable_metrics", True),
            enable_enhanced_rar=data.get("enable_enhanced_rar", False),
            embedding_provider=data.get("embedding_provider", "ollama"),
        )

def _parse_bool(value: str) -> bool:
    """Parse environment variable as boolean."""
    return value.lower() in ("true", "1", "yes", "on")
```

**Environment setup:**
```bash
# .env.local (add these for development)
EMBEDDING_PROVIDER=ollama
ENABLE_DSPY_EMBEDDINGS=false  # Start disabled, enable after PoC
ENABLE_CACHE=true
ENABLE_IFEVAL=true
ENABLE_METRICS=true
ENABLE_ENHANCED_RAR=false
```

---

### Task 0.5: Define Missing Ports (1 hora)

**Prop√≥sito:** Architecture compliance - create ports before adapters

```python
# hemdov/domain/ports/cache_port.py
from typing import Protocol, Any, NotRequired
from typing_extensions import Self

class CachePort(Protocol):
    """Cache interface for domain layer."""

    def get(self, key: str) -> Any | None:
        """Retrieve cached value."""
        ...

    def set(self, key: str, value: Any, ttl: int = 86400) -> None:
        """Store value with TTL."""
        ...

    def invalidate_by_version(self, version: str) -> None:
        """Invalidate all entries for a specific version."""
        ...


# hemdov/domain/ports/vectorizer_port.py
from typing import Protocol
import numpy as np
from typing import List

class VectorizerPort(Protocol):
    """Vectorizer interface for domain layer."""

    @property
    def mode(self) -> str:
        """Return current vectorizer mode ('dspy' or 'bigram')."""
        ...

    def __call__(self, texts: List[str]) -> np.ndarray:
        """Vectorize texts."""
        ...

    def get_catalog_vectors(self) -> np.ndarray:
        """Get pre-computed catalog vectors."""
        ...

    def get_usage_stats(self) -> dict:
        """Get vectorizer usage statistics."""
        ...


# hemdov/domain/ports/metrics_port.py
from typing import Protocol

class MetricsPort(Protocol):
    """Metrics collection interface for domain layer."""

    def record_knn_hit(self, used_embeddings: bool, query: str) -> None:
        """Record KNN query with usage stats."""
        ...

    def record_ifeval_result(self, score: float, passed: bool, prompt_id: str) -> None:
        """Record IFEval validation result."""
        ...

    def record_latency(self, operation: str, duration_ms: float) -> None:
        """Record operation latency."""
        ...

    def record_cache_hit(self, hit: bool, key: str) -> None:
        """Record cache hit/miss."""
        ...

    def get_knn_hit_rate(self, time_window: str = "24h") -> float:
        """Get KNN embedding usage rate."""
        ...

    def get_cache_hit_rate(self, time_window: str = "24h") -> float:
        """Get cache hit rate."""
        ...
```

---

## Fase 1: Fundamentos

### Error Handling Audit (~10% remaining)

**Archivos a auditar:**
- `intent_classifier.py`
- `complexity_analyzer.py`
- `reflexion_service.py`

**B√∫squeda de excepciones gen√©ricas:**
```bash
# Encontrar remaining `except Exception`
grep -rn "except Exception" hemdov/domain/services/
```

**Expected:** YaÂ§ßÈÉ® complete per review - solo queda ~10%

---

## Fase 2: Safety Nets

### 2.1 Cache Layer

**Schema fix:** A√±adir `NOT NULL DEFAULT 'unknown'`

```sql
-- data/cache_schema.sql (CORREGIDO)
CREATE TABLE IF NOT EXISTS cache_entries (
    cache_key TEXT PRIMARY KEY,
    prompt_object_json TEXT NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_accessed TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    access_count INTEGER DEFAULT 1,
    catalog_version TEXT NOT NULL DEFAULT 'unknown',  -- ‚úÖ FIX: Added NOT NULL
    vectorizer_mode TEXT NOT NULL DEFAULT 'bigram',  -- ‚úÖ FIX: Added NOT NULL
    ttl_seconds INTEGER DEFAULT 86400
);
```

### 2.2 IFEval Validator

**Threshold ajustable:**

```python
# hemdov/domain/services/ifeval_validator.py

class IFEvalValidator:
    def __init__(
        self,
        constraints: list[Constraint] = CONSTRAINTS,
        threshold: float = None  # ‚úÖ Allow None for calibration
    ):
        self.constraints = constraints
        # Load threshold from calibration or use default
        if threshold is None:
            threshold = self._load_calibrated_threshold()

        self.threshold = threshold

    def _load_calibrated_threshold(self) -> float:
        """Load threshold from calibration data."""
        import json
        from pathlib import Path

        calibration_path = Path("data/ifeval-calibration.json")
        if calibration_path.exists():
            with open(calibration_path) as f:
                data = json.load(f)
                # Use calibrated threshold if available
                return data.get("calibrated_threshold", 0.7)

        return 0.7  # Conservative default
```

---

## Fase 3: DSPy Integration

### ‚ö†Ô∏è Go/No-Go PoC Gate (CRITICAL)

**ANTES de implementar HybridVectorizer, ejecutar PoC:**

```python
# scripts/poc_ollama_embeddings.py
import time
import requests
import numpy as np
from pathlib import Path

def poc_ollama_embeddings():
    """Validate Ollama embeddings meet all requirements."""

    print("üß™ Running Ollama Embeddings PoC...")

    # Test 1: Embeddings generate successfully
    print("\n1Ô∏è‚É£ Testing embedding generation...")
    response = requests.post(
        "http://localhost:11434/api/embeddings",
        json={"model": "nomic-embed-text", "prompt": "test query for semantic search"}
    )

    assert response.status_code == 200, "‚ùå Ollama not responding"
    embedding = response.json()["embedding"]
    print(f"   ‚úÖ Embedding generated: {len(embedding)} dimensions")

    # Test 2: Dimensionality compatible (768)
    print("\n2Ô∏è‚É£ Testing dimension compatibility...")
    assert len(embedding) == 768, f"‚ùå Unexpected dimensions: {len(embedding)}"
    print(f"   ‚úÖ Dimensions compatible: {len(embedding)} (expected 768)")

    # Test 3: Latency <500ms
    print("\n3Ô∏è‚É£ Testing latency P95...")
    latencies = []
    for _ in range(100):
        start = time.perf_counter()
        response = requests.post(
            "http://localhost:11434/api/embeddings",
            json={"model": "nomic-embed-text", "prompt": f"test query {i}"}
        )
        end = time.perf_counter()
        latencies.append((end - start) * 1000)

    p95 = sorted(latencies)[94]  # 95th percentile
    assert p95 < 500, f"‚ùå Latency too high: {p95:.2f}ms (target: <500ms)"
    print(f"   ‚úÖ Latency P95: {p95:.2f}ms (target: <500ms)")

    # Test 4: Quality assessment
    print("\n4Ô∏è‚É£ Testing semantic quality...")
    # Compare with bigram baseline
    # This requires running KNN with both vectorizers
    # For PoC, just verify embeddings produce non-zero vectors
    embedding_norm = np.linalg.norm(embedding)
    assert embedding_norm > 0, "‚ùå Zero vector - embedding failed"
    print(f"   ‚úÖ Embedding norm: {embedding_norm:.4f} (non-zero)")

    # Save PoC results
    results = {
        "status": "PASS",
        "dimensions": len(embedding),
        "latency_p95_ms": p95,
        "latency_mean_ms": np.mean(latencies),
        "embedding_norm": float(embedding_norm),
        "recommendation": "Proceed with Ollama embeddings",
        "cost_per_month": "$0 (local)"
    }

    output_path = Path("data/poc-ollama-results.json")
    output_path.parent.mkdir(exist_ok=True)
    with open(output_path, "w") as f:
        import json
        json.dump(results, f, indent=2)

    print(f"\n‚úÖ PoC PASSED - Results saved to {output_path}")
    print(f"\nüìä PoC Summary:")
    print(f"   Dimensions: {results['dimensions']} (‚úÖ compatible)")
    print(f"   Latency P95: {results['latency_p95_ms']:.2f}ms (‚úÖ <500ms)")
    print(f"   Cost: {results['cost_per_month']}")
    print(f"\nüéØ Decision: PROCEED with Ollama embeddings")

    return results

if __name__ == "__main__":
    poc_ollama_embeddings()
```

**PoC Output Decision Matrix:**

| Criteria | Target | Ollama Result | OpenAI Fallback |
|----------|--------|---------------|-----------------|
| Dimensions | 768 or 1536 | 768 ‚úÖ | 1536 |
| Latency P95 | <500ms | ~200-400ms ‚úÖ | ~100-200ms |
| Quality | ‚â• bigram | TBD in PoC | Likely higher |
| Cost | - | $0 ‚úÖ | ~$X/month |

**Decision Rule:**
```python
if all_criteria_passed:
    decision = "ollama"
    reason = "Meets all requirements at $0 cost"
else:
    decision = "openai"
    reason = "Switch to higher quality embeddings"
```

### 3.1 Hybrid Vectorizer con Runtime Validation

**Add runtime dimension validation:**

```python
# hemdov/infrastructure/adapters/hybrid_vectorizer.py

def _dspy_vectorize(self, texts: List[str]) -> np.ndarray:
    """Vectorize using DSPy embeddings."""
    try:
        # Check if DSPy LM supports embeddings
        if not hasattr(self.dspy_lm, 'embed'):
            logger.warning("DSPy LM doesn't support embeddings, falling back to bigram")
            return self._bigram_vectorize(texts)

        embeddings = self.dspy_lm.embed(texts)

        # ‚úÖ FIX: Runtime dimension validation (from Architecture Review)
        VALID_DIMENSIONS = {768, 1536}
        if embeddings.shape[1] not in VALID_DIMENSIONS:
            raise ValueError(
                f"Unexpected embedding dimension: {embeddings.shape[1]}. "
                f"Expected one of {VALID_DIMENSIONS}. "
                f"Cannot use with catalog vectors."
            )

        self.dspy_usage_count += len(texts)
        return embeddings

    except (TimeoutError, ConnectionError) as e:
        logger.warning(f"DSPy embeddings failed: {e}, falling back to bigram")
        return self._bigram_vectorize(texts)
```

### 3.2 Catalog Vector Persistence

**Add persistence to avoid recomputation:**

```python
# hemdov/infrastructure/adapters/hybrid_vectorizer.py

class HybridVectorizer:
    def __init__(self, ...):
        # ... existing init ...
        self._cache_dir = Path("cache/embeddings")
        self._cache_dir.mkdir(parents=True, exist_ok=True)

    def get_catalog_vectors(self) -> np.ndarray:
        """Get pre-computed catalog vectors (with persistence)."""

        if self.mode == "dspy" and self.dspy_lm is not None:
            # ‚úÖ FIX: Check for persisted vectors first
            cache_path = self._cache_dir / f"catalog-{self.catalog_version}.npz"

            if cache_path.exists():
                logger.info(f"Loading cached DSPy catalog vectors from {cache_path}")
                return np.load(cache_path)["vectors"]

            # Not cached - compute and persist
            logger.info("Computing DSPy catalog vectors (first time)...")
            catalog_vectors = self._dspy_compute_and_persist_catalog()

            return catalog_vectors
        else:
            return self.bigram_catalog_vectors

    def _dspy_compute_and_persist_catalog(self) -> np.ndarray:
        """Compute and persist catalog vectors."""
        from hemdov.infrastructure.repositories.component_catalog_repository import ComponentCatalogRepository
        catalog = ComponentCatalogRepository(self.catalog_path).load()
        catalog_texts = [ex.input_idea for ex in catalog.examples]

        vectors = self._dspy_vectorize(catalog_texts)

        # Persist to disk
        cache_path = self._cache_dir / f"catalog-{self.catalog_version}.npz"
        np.savez(cache_path, vectors=vectors)
        logger.info(f"Persisted {len(vectors)} catalog vectors to {cache_path}")

        return vectors
```

---

## Fase 4: Observability

### Metrics Collector with Complete Port

```python
# hemdov/infrastructure/telemetry/sqlite_metrics_adapter.py

class SQLiteMetricsAdapter:
    """SQLite-based metrics implementation."""

    def __init__(self, db_path: str = "data/metrics.db"):
        self.conn = sqlite3.connect(db_path)
        self._init_schema()

    def record_knn_hit(self, used_embeddings: bool, query: str) -> None:
        """Record KNN query with usage stats."""
        import json
        self.conn.execute(
            "INSERT INTO metrics_events (metric_type, data) VALUES (?, ?)",
            ("knn_hit", json.dumps({
                "used_embeddings": used_embeddings,
                "query_hash": hash(query),
                "vectorizer_mode": "dspy" if used_embeddings else "bigram"
            }))
        )
        self.conn.commit()

    def record_cache_hit(self, hit: bool, key: str) -> None:
        """Record cache hit/miss."""
        import json
        self.conn.execute(
            "INSERT INTO metrics_events (metric_type, data) VALUES (?, ?)",
            ("cache_hit", json.dumps({"hit": hit, "key_hash": hash(key)}))
        )
        self.conn.commit()

    def get_cache_hit_rate(self, time_window: str = "24h") -> float:
        """Get cache hit rate."""
        import json
        cursor = self.conn.execute(
            f"""SELECT data FROM metrics_events
                WHERE metric_type = 'cache_hit'
                AND timestamp > datetime('now', '-{time_window}')"""
        )
        results = [json.loads(row[0]) for row in cursor]

        if not results:
            return 0.0

        hit_count = sum(1 for r in results if r["hit"])
        return hit_count / len(results)

    def get_knn_hit_rate(self, time_window: str = "24h") -> float:
        """Get KNN embedding usage rate."""
        import json
        cursor = self.conn.execute(
            f"""SELECT data FROM metrics_events
                WHERE metric_type = 'knn_hit'
                AND timestamp > datetime('now', '-{time_window}')"""
        )
        results = [json.loads(row[0]) for row in cursor]

        if not results:
            return 0.0

        embedding_count = sum(1 for r in results if r["used_embeddings"])
        return embedding_count / len(results)
```

---

## üìèÔ∏è Definition of Done - v3.0 UPDATED

### Fase 0 - Done ‚úÖ
- [ ] Ollama installed with `nomic-embed-text` downloaded
- [ ] IFEval calibration bootstrapped from catalog (threshold determined)
- [ ] Baseline metrics saved to `data/baseline-v3.0.json`
- [ ] Feature flags infrastructure created
- [ ] Ports defined (CachePort, VectorizerPort, MetricsPort)
- [ ] All tests passing

### Fase 1 - Done
- [ ] No `except Exception` remains in domain services
- [ ] Error types documented
- [ ] Remaining edge cases handled

### Fase 2 - Done
- [ ] Cache functional with ‚â•40% hit rate (after 48h)
- [ ] IFEval calibrated with threshold from data (not assumed 0.8)
- [ ] Both feature flags tested (on/off)

### Fase 3 - Done (Go/No-Go at PoC)
- [ ] ‚úÖ Ollama PoC passed ALL criteria
- [ ] HybridVectorizer in use with ‚â•80% embedding rate
- [ ] Fallback rate <20%
- [ ] Latency P95 ‚â§10s (end-to-end)
- [ ] Catalog vectors persisted (no recomputation)
- [ ] Runtime dimension validation in place

### Fase 4 - Done
- [ ] Metrics collecting all 5 categories + cache hits
- [ ] KNN hit rate visible in metrics
- [ ] Cache hit rate tracked

---

## üö¶ Go/No-Go Decision Points - v3.0 UPDATED

| Decision Point | Criteria | Go/No-Go |
|----------------|----------|----------|
| **After Fase 0** | Ollama installed, calibration bootstrapped, baseline measured | ‚úÖ AUTO (if setup complete) |
| **After Fase 2** | Cache working, IFEval threshold determined | ‚úÖ AUTO (if calibraci√≥n completa) |
| **‚ö†Ô∏è Fase 3 PoC** | Ollama PoC: dimensions=768, latency<500ms, quality‚â•baseline | ‚ö†Ô∏è MANUAL (ejecutar script PoC) |
| **After Fase 3** | Embedding rate‚â•80%, latency‚â§10s, fallback<20% | ‚ö†Ô∏è MANUAL (validar m√©tricas) |

### Fase 3 PoC Script (REQUIRED before Fase 3)

```bash
# Run this BEFORE implementing HybridVectorizer
uv run python scripts/poc_ollama_embeddings.py

# Expected output:
# ‚úÖ Dimensions: 768 (compatible)
# ‚úÖ Latency P95: ~300ms (<500ms)
# ‚úÖ Cost: $0/month
# üéØ Decision: PROCEED with Ollama
```

**If PoC FAILS:**
```bash
# Switch to OpenAI
export EMBEDDING_PROVIDER=openai
export OPENAI_API_KEY=sk-...
# Recalculate cost budget
```

---

## üìù Decision Log - v3.0 UPDATED

| Date | Decision | Rationale | Source |
|------|----------|-----------|--------|
| 2026-01-13 | Reorder phases | Measure before improving | Review v2.0 |
| 2026-01-13 | Router pattern | Vector dimension incompatibility | Architecture v2.0 |
| 2026-01-13 | Cache in infrastructure | Hexagonal architecture compliance | Architecture v2.0 |
| 2026-01-13 | Defer Enhanced RaR | Scope creep, not critical | Risk v2.0 |
| 2026-01-13 | **Ollama for PoC** | **$0 cost, local, immediate availability** | Sequential v3.0 ‚ú® |
| 2026-01-13 | **Bootstrap calibration** | **Use existing 109 catalog examples** | Sequential v3.0 ‚ú® |
| 2026-01-13 | **Defer cost budget** | **Only calculate if Ollama fails PoC** | Sequential v3.0 ‚ú® |

---

## üîó Referencias

- Plan v2.0: `docs/plan/2026-01-13-nlac-pipeline-improvements.md`
- Multi-agent review v2.0: 2026-01-13 (4 agents)
- Sequential thinking analysis: 2026-01-13
- Backend architecture: `docs/backend/README.md`
- Optimizaciones: `OPTIMIZATIONS.md`

---

**Plan Version:** 3.0 (Sequential Thinking Analysis Applied)
**Last Updated:** 2026-01-13
**Status:** ‚úÖ READY FOR IMPLEMENTATION
**Next Step:** Ejecutar Fase 0 Task 0.1 (Setup Ollama)
